{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:57.555241Z",
     "iopub.status.busy": "2023-06-14T16:35:57.554778Z",
     "iopub.status.idle": "2023-06-14T16:35:57.565270Z",
     "shell.execute_reply": "2023-06-14T16:35:57.564110Z",
     "shell.execute_reply.started": "2023-06-14T16:35:57.555211Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:57.567414Z",
     "iopub.status.busy": "2023-06-14T16:35:57.566894Z",
     "iopub.status.idle": "2023-06-14T16:35:57.696624Z",
     "shell.execute_reply": "2023-06-14T16:35:57.695513Z",
     "shell.execute_reply.started": "2023-06-14T16:35:57.567384Z"
    }
   },
   "outputs": [],
   "source": [
    "companies_df = pd.read_csv(\n",
    "  \"../data/companies_cleaned.csv\", usecols=[\"name\"]\n",
    ")\n",
    "\n",
    "companies = companies_df.name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:57.698210Z",
     "iopub.status.busy": "2023-06-14T16:35:57.697864Z",
     "iopub.status.idle": "2023-06-14T16:35:57.704999Z",
     "shell.execute_reply": "2023-06-14T16:35:57.703879Z",
     "shell.execute_reply.started": "2023-06-14T16:35:57.698176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126021"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:57.706802Z",
     "iopub.status.busy": "2023-06-14T16:35:57.706476Z",
     "iopub.status.idle": "2023-06-14T16:35:57.717722Z",
     "shell.execute_reply": "2023-06-14T16:35:57.716894Z",
     "shell.execute_reply.started": "2023-06-14T16:35:57.706774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ibm', 'walmart', 'microsoft', 'pwc', 'deloitte']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:57.719071Z",
     "iopub.status.busy": "2023-06-14T16:35:57.718682Z",
     "iopub.status.idle": "2023-06-14T16:35:57.744309Z",
     "shell.execute_reply": "2023-06-14T16:35:57.742967Z",
     "shell.execute_reply.started": "2023-06-14T16:35:57.719038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([len(c) for c in companies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:57.746855Z",
     "iopub.status.busy": "2023-06-14T16:35:57.746430Z",
     "iopub.status.idle": "2023-06-14T16:35:57.770087Z",
     "shell.execute_reply": "2023-06-14T16:35:57.768903Z",
     "shell.execute_reply.started": "2023-06-14T16:35:57.746782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(c) for c in companies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:57.773171Z",
     "iopub.status.busy": "2023-06-14T16:35:57.772749Z",
     "iopub.status.idle": "2023-06-14T16:35:57.794227Z",
     "shell.execute_reply": "2023-06-14T16:35:57.793383Z",
     "shell.execute_reply.started": "2023-06-14T16:35:57.773139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.524261829377643"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(c) for c in companies]) / len(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:57.795891Z",
     "iopub.status.busy": "2023-06-14T16:35:57.795549Z",
     "iopub.status.idle": "2023-06-14T16:35:57.829886Z",
     "shell.execute_reply": "2023-06-14T16:35:57.828575Z",
     "shell.execute_reply.started": "2023-06-14T16:35:57.795852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = sorted(set(\"\".join(companies)))\n",
    "alphabet.insert(0, '.')\n",
    "num_letters = len(alphabet)\n",
    "num_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:57.831548Z",
     "iopub.status.busy": "2023-06-14T16:35:57.831203Z",
     "iopub.status.idle": "2023-06-14T16:35:57.842987Z",
     "shell.execute_reply": "2023-06-14T16:35:57.841896Z",
     "shell.execute_reply.started": "2023-06-14T16:35:57.831519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "combinations = list(itertools.product(alphabet, repeat=2))\n",
    "combinations = [''.join(comb) for comb in combinations]\n",
    "len(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:57.845218Z",
     "iopub.status.busy": "2023-06-14T16:35:57.844680Z",
     "iopub.status.idle": "2023-06-14T16:35:57.853115Z",
     "shell.execute_reply": "2023-06-14T16:35:57.852163Z",
     "shell.execute_reply.started": "2023-06-14T16:35:57.845176Z"
    }
   },
   "outputs": [],
   "source": [
    "strtoint = {j: i for i, j in enumerate(alphabet)}\n",
    "inttostr = {i: j for i, j in enumerate(alphabet)}\n",
    "\n",
    "strtoint_bi = {j: i for i, j in enumerate(combinations)}\n",
    "inttostr_bi = {i: j for i, j in enumerate(combinations)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:48:15.757683Z",
     "iopub.status.busy": "2023-06-14T17:48:15.757247Z",
     "iopub.status.idle": "2023-06-14T17:48:15.763106Z",
     "shell.execute_reply": "2023-06-14T17:48:15.762050Z",
     "shell.execute_reply.started": "2023-06-14T17:48:15.757648Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:48:36.171579Z",
     "iopub.status.busy": "2023-06-14T17:48:36.170830Z",
     "iopub.status.idle": "2023-06-14T17:48:36.176673Z",
     "shell.execute_reply": "2023-06-14T17:48:36.175322Z",
     "shell.execute_reply.started": "2023-06-14T17:48:36.171543Z"
    }
   },
   "outputs": [],
   "source": [
    "E = torch.zeros((len(alphabet) * len(alphabet), len(alphabet)), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:48:36.767182Z",
     "iopub.status.busy": "2023-06-14T17:48:36.766763Z",
     "iopub.status.idle": "2023-06-14T17:48:58.491975Z",
     "shell.execute_reply": "2023-06-14T17:48:58.490814Z",
     "shell.execute_reply.started": "2023-06-14T17:48:36.767151Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126021/126021 [00:21<00:00, 5803.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for word in tqdm.tqdm(companies):  \n",
    "  word = ['.', '.'] + list(word) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(word, word[1:], word[2:]):\n",
    "    int1, int2, int3 = strtoint[ch1], strtoint[ch2], strtoint[ch3]\n",
    "    int12 = strtoint_bi[ch1+ch2]\n",
    "    E[int12, int3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:49:08.954097Z",
     "iopub.status.busy": "2023-06-14T17:49:08.953162Z",
     "iopub.status.idle": "2023-06-14T17:49:08.959108Z",
     "shell.execute_reply": "2023-06-14T17:49:08.957936Z",
     "shell.execute_reply.started": "2023-06-14T17:49:08.954053Z"
    }
   },
   "outputs": [],
   "source": [
    "P = (E+1).float() # +1 is for model smoothing\n",
    "P /= P.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:49:22.960469Z",
     "iopub.status.busy": "2023-06-14T17:49:22.960085Z",
     "iopub.status.idle": "2023-06-14T17:49:22.967758Z",
     "shell.execute_reply": "2023-06-14T17:49:22.966346Z",
     "shell.execute_reply.started": "2023-06-14T17:49:22.960440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([729, 27])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:49:31.281525Z",
     "iopub.status.busy": "2023-06-14T17:49:31.281131Z",
     "iopub.status.idle": "2023-06-14T17:49:31.291363Z",
     "shell.execute_reply": "2023-06-14T17:49:31.289621Z",
     "shell.execute_reply.started": "2023-06-14T17:49:31.281496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:49:34.477230Z",
     "iopub.status.busy": "2023-06-14T17:49:34.476521Z",
     "iopub.status.idle": "2023-06-14T17:49:49.406374Z",
     "shell.execute_reply": "2023-06-14T17:49:49.405072Z",
     "shell.execute_reply.started": "2023-06-14T17:49:34.477196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood=tensor(-2968869.2500)\n",
      "neg_logl=tensor(2968869.2500)\n",
      "loss=tensor(2.4735)\n"
     ]
    }
   ],
   "source": [
    "# compute the loss on the entire dataset or a single string\n",
    "\n",
    "n = 0\n",
    "log_likelihood = 0\n",
    "\n",
    "# for word in [\"openai\"]:\n",
    "for word in companies:\n",
    "  word = ['.', '.'] + list(word) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(word, word[1:], word[2:]):\n",
    "    ix1 = strtoint_bi[ch1+ch2]\n",
    "    ix2 = strtoint[ch3]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "\n",
    "print(f\"{log_likelihood=}\")\n",
    "neg_logl = -log_likelihood\n",
    "print(f\"{neg_logl=}\")\n",
    "loss = neg_logl/n\n",
    "print(f\"{loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:50:40.213113Z",
     "iopub.status.busy": "2023-06-14T17:50:40.212281Z",
     "iopub.status.idle": "2023-06-14T17:50:40.230436Z",
     "shell.execute_reply": "2023-06-14T17:50:40.229146Z",
     "shell.execute_reply.started": "2023-06-14T17:50:40.213070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news\n",
      "maibervemacer\n",
      "ron\n",
      "tegoft\n",
      "cointsouseals\n",
      "tv\n",
      "xtioudisonvismadvienb\n",
      "clestenwedon\n",
      "lorly\n",
      "chrce\n",
      "derfamealm\n",
      "perntrappyressegroosayrogink\n",
      "smitic\n",
      "clivareptoskel\n",
      "synanue\n",
      "myduce\n",
      "waysitythinne\n",
      "frionessaw\n",
      "aumeeducar\n",
      "ica\n"
     ]
    }
   ],
   "source": [
    "# sampling from the model\n",
    "g = torch.Generator().manual_seed(10110609)\n",
    "\n",
    "for i in range(20):\n",
    "    letters = '..'\n",
    "\n",
    "    word = ''\n",
    "\n",
    "    while True:\n",
    "        idx = strtoint_bi[letters]\n",
    "        # p = E[idx].float()\n",
    "        # p = p / p.sum()\n",
    "        p = P[idx]\n",
    "        next_letter_ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g)\n",
    "        letter = inttostr[next_letter_ix.item()]\n",
    "\n",
    "        if letter == '.':\n",
    "            break\n",
    "\n",
    "        word += letter\n",
    "        letters = letters[1:] + letter\n",
    "\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:57.855025Z",
     "iopub.status.busy": "2023-06-14T16:35:57.854619Z",
     "iopub.status.idle": "2023-06-14T16:35:57.865069Z",
     "shell.execute_reply": "2023-06-14T16:35:57.863901Z",
     "shell.execute_reply.started": "2023-06-14T16:35:57.854991Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "  xs, ys = [], []\n",
    "  for word in words:\n",
    "    word = ['.', '.'] + list(word) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(word, word[1:], word[2:]):\n",
    "      ix1 = strtoint_bi[ch1+ch2]\n",
    "      ix2 = strtoint[ch3]\n",
    "      xs.append(ix1)\n",
    "      ys.append(ix2)\n",
    "      \n",
    "  xs = torch.tensor(xs)\n",
    "  ys = torch.tensor(ys)\n",
    "\n",
    "  return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:57.866804Z",
     "iopub.status.busy": "2023-06-14T16:35:57.866399Z",
     "iopub.status.idle": "2023-06-14T16:35:59.846402Z",
     "shell.execute_reply": "2023-06-14T16:35:59.845295Z",
     "shell.execute_reply.started": "2023-06-14T16:35:57.866776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959832, 120091, 120334)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting data into train, dev and test sets\n",
    "import random\n",
    "\n",
    "random.shuffle(companies)\n",
    "\n",
    "n1 = int(len(companies) * 0.8)\n",
    "n2 = int(len(companies) * 0.9)\n",
    "\n",
    "X_train, y_train = build_dataset(companies[:n1])\n",
    "X_dev, y_dev = build_dataset(companies[n1:n2])\n",
    "X_test, y_test = build_dataset(companies[n2:])\n",
    "\n",
    "train_size = X_train.nelement()\n",
    "\n",
    "len(X_train), len(X_dev), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:59.848125Z",
     "iopub.status.busy": "2023-06-14T16:35:59.847742Z",
     "iopub.status.idle": "2023-06-14T16:35:59.854268Z",
     "shell.execute_reply": "2023-06-14T16:35:59.852980Z",
     "shell.execute_reply.started": "2023-06-14T16:35:59.848095Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = torch.Generator().manual_seed(10110609)\n",
    "W = torch.randn((num_letters*num_letters, num_letters), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:59.858090Z",
     "iopub.status.busy": "2023-06-14T16:35:59.856964Z",
     "iopub.status.idle": "2023-06-14T16:35:59.867666Z",
     "shell.execute_reply": "2023-06-14T16:35:59.866445Z",
     "shell.execute_reply.started": "2023-06-14T16:35:59.858050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([729, 27])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:59.869425Z",
     "iopub.status.busy": "2023-06-14T16:35:59.869109Z",
     "iopub.status.idle": "2023-06-14T16:35:59.876873Z",
     "shell.execute_reply": "2023-06-14T16:35:59.876149Z",
     "shell.execute_reply.started": "2023-06-14T16:35:59.869397Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:33:24.105769Z",
     "iopub.status.busy": "2023-06-14T16:33:24.105370Z",
     "iopub.status.idle": "2023-06-14T16:33:24.111087Z",
     "shell.execute_reply": "2023-06-14T16:33:24.110184Z",
     "shell.execute_reply.started": "2023-06-14T16:33:24.105741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xenc @ W\n",
    "# (ts, 729) @ (729, 27) => (ts, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T13:23:26.729776Z",
     "iopub.status.busy": "2023-06-14T13:23:26.729405Z",
     "iopub.status.idle": "2023-06-14T13:23:33.733472Z",
     "shell.execute_reply": "2023-06-14T13:23:33.732470Z",
     "shell.execute_reply.started": "2023-06-14T13:23:26.729744Z"
    }
   },
   "outputs": [],
   "source": [
    "# forward propogation\n",
    "xenc = F.one_hot(X_train, num_classes=num_letters*num_letters).float()\n",
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(train_size), y_train].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T13:20:00.761532Z",
     "iopub.status.busy": "2023-06-14T13:20:00.761164Z",
     "iopub.status.idle": "2023-06-14T13:20:00.770211Z",
     "shell.execute_reply": "2023-06-14T13:20:00.768610Z",
     "shell.execute_reply.started": "2023-06-14T13:20:00.761504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5262298583984375"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T13:20:06.021366Z",
     "iopub.status.busy": "2023-06-14T13:20:06.021011Z",
     "iopub.status.idle": "2023-06-14T13:20:06.946472Z",
     "shell.execute_reply": "2023-06-14T13:20:06.945154Z",
     "shell.execute_reply.started": "2023-06-14T13:20:06.021340Z"
    }
   },
   "outputs": [],
   "source": [
    "# backward propogation\n",
    "W.grad = None\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T13:20:10.375548Z",
     "iopub.status.busy": "2023-06-14T13:20:10.375221Z",
     "iopub.status.idle": "2023-06-14T13:20:10.380707Z",
     "shell.execute_reply": "2023-06-14T13:20:10.379674Z",
     "shell.execute_reply.started": "2023-06-14T13:20:10.375528Z"
    }
   },
   "outputs": [],
   "source": [
    "# update the parameters\n",
    "W.data += -150 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T13:20:11.668696Z",
     "iopub.status.busy": "2023-06-14T13:20:11.668330Z",
     "iopub.status.idle": "2023-06-14T13:20:11.674317Z",
     "shell.execute_reply": "2023-06-14T13:20:11.673108Z",
     "shell.execute_reply.started": "2023-06-14T13:20:11.668668Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3.755063533782959\n",
    "# 3.754981517791748\n",
    "# 3.754899740219116\n",
    "# 3.7548177242279053\n",
    "# 3.715470552444458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 2.4736 for trigram model\n",
    "# I expect to see this number by the end of neural net training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:24:22.228112Z",
     "iopub.status.busy": "2023-06-14T17:24:22.227594Z",
     "iopub.status.idle": "2023-06-14T17:34:06.925816Z",
     "shell.execute_reply": "2023-06-14T17:34:06.924564Z",
     "shell.execute_reply.started": "2023-06-14T17:24:22.228074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 2.5592660903930664\n",
      "1 / 2.559004545211792\n",
      "2 / 2.558743953704834\n",
      "3 / 2.558485507965088\n",
      "4 / 2.5582287311553955\n",
      "5 / 2.5579733848571777\n",
      "6 / 2.557720184326172\n",
      "7 / 2.5574681758880615\n",
      "8 / 2.557218313217163\n",
      "9 / 2.5569698810577393\n",
      "10 / 2.55672287940979\n",
      "11 / 2.5564780235290527\n",
      "12 / 2.556234359741211\n",
      "13 / 2.555992603302002\n",
      "14 / 2.5557518005371094\n",
      "15 / 2.5555131435394287\n",
      "16 / 2.5552754402160645\n",
      "17 / 2.555039882659912\n",
      "18 / 2.554805278778076\n",
      "19 / 2.554572343826294\n",
      "20 / 2.5543410778045654\n",
      "21 / 2.5541110038757324\n",
      "22 / 2.553882360458374\n",
      "23 / 2.5536553859710693\n",
      "24 / 2.553429365158081\n",
      "25 / 2.5532054901123047\n",
      "26 / 2.5529825687408447\n",
      "27 / 2.5527613162994385\n",
      "28 / 2.5525410175323486\n",
      "29 / 2.5523221492767334\n",
      "30 / 2.5521047115325928\n",
      "31 / 2.551888942718506\n",
      "32 / 2.5516738891601562\n",
      "33 / 2.5514605045318604\n",
      "34 / 2.551248073577881\n",
      "35 / 2.551037311553955\n",
      "36 / 2.5508275032043457\n",
      "37 / 2.55061936378479\n",
      "38 / 2.550412178039551\n",
      "39 / 2.550206184387207\n",
      "40 / 2.550001621246338\n",
      "41 / 2.5497982501983643\n",
      "42 / 2.549596071243286\n",
      "43 / 2.5493950843811035\n",
      "44 / 2.5491952896118164\n",
      "45 / 2.5489964485168457\n",
      "46 / 2.5487990379333496\n",
      "47 / 2.548602819442749\n",
      "48 / 2.548407554626465\n",
      "49 / 2.548213243484497\n",
      "50 / 2.548020124435425\n",
      "51 / 2.547828435897827\n",
      "52 / 2.5476372241973877\n",
      "53 / 2.547447919845581\n",
      "54 / 2.547259569168091\n",
      "55 / 2.547072172164917\n",
      "56 / 2.5468852519989014\n",
      "57 / 2.5467000007629395\n",
      "58 / 2.546515703201294\n",
      "59 / 2.546332597732544\n",
      "60 / 2.546149969100952\n",
      "61 / 2.545969009399414\n",
      "62 / 2.5457887649536133\n",
      "63 / 2.545609474182129\n",
      "64 / 2.545431613922119\n",
      "65 / 2.5452539920806885\n",
      "66 / 2.5450780391693115\n",
      "67 / 2.5449025630950928\n",
      "68 / 2.5447280406951904\n",
      "69 / 2.5445549488067627\n",
      "70 / 2.5443825721740723\n",
      "71 / 2.5442111492156982\n",
      "72 / 2.5440406799316406\n",
      "73 / 2.543870687484741\n",
      "74 / 2.5437021255493164\n",
      "75 / 2.543534517288208\n",
      "76 / 2.543367862701416\n",
      "77 / 2.5432016849517822\n",
      "78 / 2.543036699295044\n",
      "79 / 2.542872428894043\n",
      "80 / 2.5427091121673584\n",
      "81 / 2.542546510696411\n",
      "82 / 2.5423853397369385\n",
      "83 / 2.542224407196045\n",
      "84 / 2.5420644283294678\n",
      "85 / 2.541905641555786\n",
      "86 / 2.5417470932006836\n",
      "87 / 2.5415899753570557\n",
      "88 / 2.541433334350586\n",
      "89 / 2.5412776470184326\n",
      "90 / 2.5411229133605957\n",
      "91 / 2.540968894958496\n",
      "92 / 2.540815591812134\n",
      "93 / 2.5406627655029297\n",
      "94 / 2.540510654449463\n",
      "95 / 2.54036021232605\n",
      "96 / 2.5402097702026367\n",
      "97 / 2.540060520172119\n",
      "98 / 2.539911985397339\n",
      "99 / 2.539763927459717\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    # forward propogation\n",
    "    xenc = F.one_hot(X_train, num_classes=num_letters*num_letters).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(train_size), y_train].log().mean() + 0.01*(W**2).mean() # last part is regularization\n",
    "    print(f\"{i} / {loss.item()}\")\n",
    "    \n",
    "    # backward propogation\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update the parameters\n",
    "    W.data += -100 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:52:23.947781Z",
     "iopub.status.busy": "2023-06-14T17:52:23.947336Z",
     "iopub.status.idle": "2023-06-14T17:52:23.995251Z",
     "shell.execute_reply": "2023-06-14T17:52:23.994239Z",
     "shell.execute_reply.started": "2023-06-14T17:52:23.947745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newqxvfhhwor\n",
      "prier\n",
      "ron\n",
      "tegoft\n",
      "coivisouseals\n",
      "tv\n",
      "xtioudisonvzsmadvienbeclestenwedon\n",
      "lorly\n",
      "chr\n",
      "daltheatealm\n",
      "pernxtsupgralvegroos\n",
      "yougkill\n",
      "mitic\n",
      "clivareptoskil\n",
      "synanue\n",
      "myducurchesitytprobionstoressawvormeeducti\n",
      "ica\n",
      "cruzzhworler\n",
      "aeqhrophille\n",
      "alwinksk\n"
     ]
    }
   ],
   "source": [
    "# sampling from the model\n",
    "g = torch.Generator().manual_seed(10110609)\n",
    "\n",
    "for i in range(20):\n",
    "    letters = '..'\n",
    "\n",
    "    word = ''\n",
    "\n",
    "    while True:\n",
    "        idx = strtoint_bi[letters]\n",
    "\n",
    "        xenc = F.one_hot(torch.tensor([idx]), num_classes=num_letters*num_letters).float()\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        \n",
    "        next_letter_ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g)\n",
    "        letter = inttostr[next_letter_ix.item()]\n",
    "\n",
    "        if letter == '.':\n",
    "            break\n",
    "\n",
    "        word += letter\n",
    "        letters = letters[1:] + letter\n",
    "\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
