{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:34:47.760219Z",
     "iopub.status.busy": "2023-06-19T05:34:47.759841Z",
     "iopub.status.idle": "2023-06-19T05:34:47.767098Z",
     "shell.execute_reply": "2023-06-19T05:34:47.766243Z",
     "shell.execute_reply.started": "2023-06-19T05:34:47.760190Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:31.263809Z",
     "iopub.status.busy": "2023-06-19T05:29:31.261044Z",
     "iopub.status.idle": "2023-06-19T05:29:31.523282Z",
     "shell.execute_reply": "2023-06-19T05:29:31.522121Z",
     "shell.execute_reply.started": "2023-06-19T05:29:31.263773Z"
    }
   },
   "outputs": [],
   "source": [
    "companies_df = pd.read_csv(\n",
    "  \"../data/cleansed_layer/companies_usa_size_over_10.csv\", usecols=[\"name\"]\n",
    ")\n",
    "\n",
    "companies = companies_df.name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:31.525289Z",
     "iopub.status.busy": "2023-06-19T05:29:31.524905Z",
     "iopub.status.idle": "2023-06-19T05:29:31.558921Z",
     "shell.execute_reply": "2023-06-19T05:29:31.557945Z",
     "shell.execute_reply.started": "2023-06-19T05:29:31.525252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 examples:  ['equinoxys', 'biassync', 'taggpay', 'touchpointe', 'rxfit']\n",
      "Length: 91073\n",
      "Max length: 16\n",
      "Min length: 3\n",
      "Avg length: 8.164823822647767\n"
     ]
    }
   ],
   "source": [
    "print(\"5 examples: \", companies[:5])\n",
    "print(f\"Length: {len(companies)}\")\n",
    "print(f\"Max length: {max([len(c) for c in companies])}\")\n",
    "print(f\"Min length: {min([len(c) for c in companies])}\")\n",
    "avg_len = sum([len(c) for c in companies]) / len(companies)\n",
    "print(f\"Avg length: {avg_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:31.561906Z",
     "iopub.status.busy": "2023-06-19T05:29:31.561496Z",
     "iopub.status.idle": "2023-06-19T05:29:31.584751Z",
     "shell.execute_reply": "2023-06-19T05:29:31.583762Z",
     "shell.execute_reply.started": "2023-06-19T05:29:31.561874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_alphabet=27\n",
      "len(combinations)=729\n"
     ]
    }
   ],
   "source": [
    "alphabet = sorted(set(\"\".join(companies)))\n",
    "alphabet.insert(0, '.')\n",
    "len_alphabet = len(alphabet)\n",
    "print(f\"{len_alphabet=}\")\n",
    "\n",
    "combinations = list(itertools.product(alphabet, repeat=2))\n",
    "combinations = [''.join(comb) for comb in combinations]\n",
    "print(f\"{len(combinations)=}\")\n",
    "\n",
    "strtoint = {j: i for i, j in enumerate(alphabet)}\n",
    "inttostr = {i: j for i, j in enumerate(alphabet)}\n",
    "\n",
    "strtoint_bi = {j: i for i, j in enumerate(combinations)}\n",
    "inttostr_bi = {i: j for i, j in enumerate(combinations)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:31.586507Z",
     "iopub.status.busy": "2023-06-19T05:29:31.586112Z",
     "iopub.status.idle": "2023-06-19T05:29:31.657805Z",
     "shell.execute_reply": "2023-06-19T05:29:31.656658Z",
     "shell.execute_reply.started": "2023-06-19T05:29:31.586476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:31.660251Z",
     "iopub.status.busy": "2023-06-19T05:29:31.659567Z",
     "iopub.status.idle": "2023-06-19T05:29:31.667728Z",
     "shell.execute_reply": "2023-06-19T05:29:31.666895Z",
     "shell.execute_reply.started": "2023-06-19T05:29:31.660217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA was enable on the kaggle kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:31.670035Z",
     "iopub.status.busy": "2023-06-19T05:29:31.669380Z",
     "iopub.status.idle": "2023-06-19T05:29:31.677023Z",
     "shell.execute_reply": "2023-06-19T05:29:31.676462Z",
     "shell.execute_reply.started": "2023-06-19T05:29:31.670003Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "  xs, ys = [], []\n",
    "  for word in words:\n",
    "    word = ['.', '.'] + list(word) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(word, word[1:], word[2:]):\n",
    "      ix1 = strtoint_bi[ch1+ch2]\n",
    "      ix2 = strtoint[ch3]\n",
    "      xs.append(ix1)\n",
    "      ys.append(ix2)\n",
    "      \n",
    "  xs = torch.tensor(xs, device=device)\n",
    "  ys = torch.tensor(ys, device=device)\n",
    "\n",
    "  return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:31.678920Z",
     "iopub.status.busy": "2023-06-19T05:29:31.678342Z",
     "iopub.status.idle": "2023-06-19T05:29:37.404299Z",
     "shell.execute_reply": "2023-06-19T05:29:37.403229Z",
     "shell.execute_reply.started": "2023-06-19T05:29:31.678890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Example after shuffling:  ['managedoffice', 'idmatrixindia', 'sightmd', 'popshelf', 'jaroop']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(668185, 83202, 83281)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting data into train, dev and test sets\n",
    "random.seed(10110609)\n",
    "random.shuffle(companies)\n",
    "print(\"5 Example after shuffling: \", companies[:5])\n",
    "\n",
    "n1 = int(len(companies) * 0.8)\n",
    "n2 = int(len(companies) * 0.9)\n",
    "\n",
    "X_train, y_train = build_dataset(companies[:n1])\n",
    "X_dev, y_dev = build_dataset(companies[n1:n2])\n",
    "X_test, y_test = build_dataset(companies[n2:])\n",
    "\n",
    "train_size = X_train.nelement()\n",
    "test_size = X_test.nelement()\n",
    "dev_size = X_dev.nelement()\n",
    "\n",
    "len(X_train), len(X_dev), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:37.406055Z",
     "iopub.status.busy": "2023-06-19T05:29:37.405636Z",
     "iopub.status.idle": "2023-06-19T05:29:37.412190Z",
     "shell.execute_reply": "2023-06-19T05:29:37.411296Z",
     "shell.execute_reply.started": "2023-06-19T05:29:37.406020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7dee148e7d30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:37.416117Z",
     "iopub.status.busy": "2023-06-19T05:29:37.415644Z",
     "iopub.status.idle": "2023-06-19T05:29:37.427572Z",
     "shell.execute_reply": "2023-06-19T05:29:37.426675Z",
     "shell.execute_reply.started": "2023-06-19T05:29:37.416085Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:37.429819Z",
     "iopub.status.busy": "2023-06-19T05:29:37.428786Z",
     "iopub.status.idle": "2023-06-19T05:29:37.451089Z",
     "shell.execute_reply": "2023-06-19T05:29:37.450292Z",
     "shell.execute_reply.started": "2023-06-19T05:29:37.429788Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = torch.Generator().manual_seed(10110609)\n",
    "W = torch.randn((len_alphabet*len_alphabet, len_alphabet), requires_grad=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xenc @ W\n",
    "# (ts, 729) @ (729, 27) => (ts, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propogation\n",
    "xenc = F.one_hot(X_train, num_classes=len_alphabet*len_alphabet).float().to(device)\n",
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(train_size, device=device), y_train].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward propogation\n",
    "W.grad = None\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the parameters\n",
    "W.data += -150 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.755063533782959\n",
    "# 3.754981517791748\n",
    "# 3.754899740219116\n",
    "# 3.7548177242279053\n",
    "# 3.715470552444458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss=tensor(2.4969) for trigram model\n",
    "# I expect to see this number by the end of neural net training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:55.461549Z",
     "iopub.status.busy": "2023-06-19T05:29:55.461203Z",
     "iopub.status.idle": "2023-06-19T05:29:55.468113Z",
     "shell.execute_reply": "2023-06-19T05:29:55.466917Z",
     "shell.execute_reply.started": "2023-06-19T05:29:55.461521Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(X, y, size):\n",
    "    xenc = F.one_hot(X, num_classes=len_alphabet*len_alphabet).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(size), y].log().mean() + 0.01*(W**2).mean() # last part is regularization\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:55.826198Z",
     "iopub.status.busy": "2023-06-19T05:29:55.825464Z",
     "iopub.status.idle": "2023-06-19T05:29:55.835001Z",
     "shell.execute_reply": "2023-06-19T05:29:55.834165Z",
     "shell.execute_reply.started": "2023-06-19T05:29:55.826160Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = torch.Generator().manual_seed(10110609)\n",
    "W = torch.randn((len_alphabet*len_alphabet, len_alphabet), requires_grad=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:58.050886Z",
     "iopub.status.busy": "2023-06-19T05:29:58.050536Z",
     "iopub.status.idle": "2023-06-19T05:29:58.055209Z",
     "shell.execute_reply": "2023-06-19T05:29:58.054328Z",
     "shell.execute_reply.started": "2023-06-19T05:29:58.050857Z"
    }
   },
   "outputs": [],
   "source": [
    "step = 0\n",
    "lossi, idxs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:29:58.342363Z",
     "iopub.status.busy": "2023-06-19T05:29:58.341688Z",
     "iopub.status.idle": "2023-06-19T05:29:58.724725Z",
     "shell.execute_reply": "2023-06-19T05:29:58.723127Z",
     "shell.execute_reply.started": "2023-06-19T05:29:58.342329Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xenc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mxenc\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xenc' is not defined"
     ]
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T05:30:36.948908Z",
     "iopub.status.busy": "2023-06-19T05:30:36.948548Z",
     "iopub.status.idle": "2023-06-19T05:32:38.029489Z",
     "shell.execute_reply": "2023-06-19T05:32:38.028515Z",
     "shell.execute_reply.started": "2023-06-19T05:30:36.948876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / train: 3.784008026123047 / dev: 3.7823433876037598\n",
      "100 / train: 3.3226256370544434 / dev: 3.3217177391052246\n",
      "200 / train: 3.1018824577331543 / dev: 3.1018524169921875\n",
      "300 / train: 2.9679830074310303 / dev: 2.9687745571136475\n",
      "400 / train: 2.8798508644104004 / dev: 2.881415367126465\n",
      "500 / train: 2.8184566497802734 / dev: 2.820681095123291\n",
      "600 / train: 2.7737903594970703 / dev: 2.7765755653381348\n",
      "700 / train: 2.7400474548339844 / dev: 2.7433245182037354\n",
      "800 / train: 2.7136728763580322 / dev: 2.717388391494751\n",
      "900 / train: 2.6924641132354736 / dev: 2.696577310562134\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    \n",
    "    # forward propogation\n",
    "    xenc = F.one_hot(X_train, num_classes=len_alphabet*len_alphabet).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(train_size), y_train].log().mean() + 0.01*(W**2).mean() # last part is regularization\n",
    "    \n",
    "    # evalute loss on the dev set\n",
    "    loss_dev = evaluate(X_dev, y_dev, dev_size)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f\"{i} / train: {loss.item()} / dev: {loss_dev.item()}\")\n",
    "    \n",
    "    # backward propogation\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update the parameters\n",
    "    W.data += -10 * W.grad\n",
    "    \n",
    "    # track params\n",
    "    lossi.append(loss.item())\n",
    "    idxs.append(step)\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6000 with -50\n",
    "# 2000 with -10 lr decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram probability based model metrics:\n",
    "\n",
    "# Evaluation on the train set: \n",
    "# log_likelihood=tensor(-1656800.5000)\n",
    "# neg_logl=tensor(1656800.5000)\n",
    "# loss=tensor(2.4796)\n",
    "\n",
    "# Evaluation on the dev set: \n",
    "# log_likelihood=tensor(-207735.1562)\n",
    "# neg_logl=tensor(207735.1562)\n",
    "# loss=tensor(2.4968)\n",
    "\n",
    "# Evaluation on the test set: \n",
    "# log_likelihood=tensor(-208261.5000)\n",
    "# neg_logl=tensor(208261.5000)\n",
    "# loss=tensor(2.5007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(idxs, lossi);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameter tuning (regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:05:01.266584Z",
     "iopub.status.busy": "2023-06-18T13:05:01.266167Z",
     "iopub.status.idle": "2023-06-18T13:05:01.271707Z",
     "shell.execute_reply": "2023-06-18T13:05:01.270766Z",
     "shell.execute_reply.started": "2023-06-18T13:05:01.266552Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "Wreg = []\n",
    "regi = [0, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T13:05:04.943567Z",
     "iopub.status.busy": "2023-06-18T13:05:04.943158Z",
     "iopub.status.idle": "2023-06-18T14:40:48.525937Z",
     "shell.execute_reply": "2023-06-18T14:40:48.524759Z",
     "shell.execute_reply.started": "2023-06-18T13:05:04.943536Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initialized the network, reg=0\n",
      "0 / train: 3.816410541534424 / dev: 3.826584577560425\n",
      "200 / train: 2.6678175926208496 / dev: 2.682584762573242\n",
      "400 / train: 2.5806243419647217 / dev: 2.5983898639678955\n",
      "600 / train: 2.547790765762329 / dev: 2.567223310470581\n",
      "800 / train: 2.530346632003784 / dev: 2.5510334968566895\n",
      "1000 / train: 2.519455671310425 / dev: 2.541217803955078\n",
      "1200 / train: 2.512000322341919 / dev: 2.5347230434417725\n",
      "1400 / train: 2.5065770149230957 / dev: 2.5301685333251953\n",
      "1600 / train: 2.50246000289917 / dev: 2.5268375873565674\n",
      "1800 / train: 2.499232530593872 / dev: 2.524322032928467\n",
      "2000 / train: 2.4966375827789307 / dev: 2.5223758220672607\n",
      "2200 / train: 2.494507074356079 / dev: 2.5208399295806885\n",
      "2400 / train: 2.492727279663086 / dev: 2.5196094512939453\n",
      "2600 / train: 2.491218328475952 / dev: 2.518611192703247\n",
      "2800 / train: 2.4899227619171143 / dev: 2.517793893814087\n",
      "3000 / train: 2.4887993335723877 / dev: 2.517120122909546\n",
      "3200 / train: 2.487816095352173 / dev: 2.5165624618530273\n",
      "3400 / train: 2.4869487285614014 / dev: 2.5160982608795166\n",
      "3600 / train: 2.486178398132324 / dev: 2.5157124996185303\n",
      "3800 / train: 2.485489845275879 / dev: 2.5153908729553223\n",
      "4000 / train: 2.4848711490631104 / dev: 2.515122890472412\n",
      "4200 / train: 2.484312057495117 / dev: 2.5149006843566895\n",
      "4400 / train: 2.483804225921631 / dev: 2.514716625213623\n",
      "4600 / train: 2.4833409786224365 / dev: 2.5145649909973145\n",
      "4800 / train: 2.482917070388794 / dev: 2.514441728591919\n",
      "5000 / train: 2.482527256011963 / dev: 2.5143418312072754\n",
      "5200 / train: 2.4824531078338623 / dev: 2.51432466506958\n",
      "5400 / train: 2.4823801517486572 / dev: 2.514308214187622\n",
      "5600 / train: 2.4823079109191895 / dev: 2.5142922401428223\n",
      "5800 / train: 2.4822373390197754 / dev: 2.514277219772339\n",
      "6000 / train: 2.4821677207946777 / dev: 2.5142629146575928\n",
      "6200 / train: 2.4820992946624756 / dev: 2.514249563217163\n",
      "6400 / train: 2.4820315837860107 / dev: 2.5142364501953125\n",
      "6600 / train: 2.4819648265838623 / dev: 2.514224052429199\n",
      "6800 / train: 2.4818994998931885 / dev: 2.5142126083374023\n",
      "\n",
      "Initialized the network, reg=0.0001\n",
      "0 / train: 3.759457588195801 / dev: 3.77215838432312\n",
      "200 / train: 2.669801712036133 / dev: 2.685035467147827\n",
      "400 / train: 2.5810840129852295 / dev: 2.5990099906921387\n",
      "600 / train: 2.5473666191101074 / dev: 2.566967010498047\n",
      "800 / train: 2.5296947956085205 / dev: 2.5505521297454834\n",
      "1000 / train: 2.5187971591949463 / dev: 2.540710210800171\n",
      "1200 / train: 2.5114071369171143 / dev: 2.534245491027832\n",
      "1400 / train: 2.506080150604248 / dev: 2.529740333557129\n",
      "1600 / train: 2.502065896987915 / dev: 2.526461601257324\n",
      "1800 / train: 2.4989349842071533 / dev: 2.523993492126465\n",
      "2000 / train: 2.4964232444763184 / dev: 2.5220859050750732\n",
      "2200 / train: 2.4943630695343018 / dev: 2.520580291748047\n",
      "2400 / train: 2.4926412105560303 / dev: 2.5193724632263184\n",
      "2600 / train: 2.491180658340454 / dev: 2.5183911323547363\n",
      "2800 / train: 2.4899256229400635 / dev: 2.5175864696502686\n",
      "3000 / train: 2.4888358116149902 / dev: 2.516921043395996\n",
      "3200 / train: 2.4878811836242676 / dev: 2.5163686275482178\n",
      "3400 / train: 2.4870378971099854 / dev: 2.515907049179077\n",
      "3600 / train: 2.4862875938415527 / dev: 2.5155210494995117\n",
      "3800 / train: 2.485616445541382 / dev: 2.515197515487671\n",
      "4000 / train: 2.4850122928619385 / dev: 2.5149266719818115\n",
      "4200 / train: 2.4844653606414795 / dev: 2.514700174331665\n",
      "4400 / train: 2.483968496322632 / dev: 2.5145111083984375\n",
      "4600 / train: 2.4835143089294434 / dev: 2.5143542289733887\n",
      "4800 / train: 2.483097791671753 / dev: 2.5142250061035156\n",
      "5000 / train: 2.4827146530151367 / dev: 2.5141193866729736\n",
      "5200 / train: 2.4826419353485107 / dev: 2.5141007900238037\n",
      "5400 / train: 2.482570171356201 / dev: 2.51408314704895\n",
      "5600 / train: 2.482499122619629 / dev: 2.514065980911255\n",
      "5800 / train: 2.4824299812316895 / dev: 2.514049768447876\n",
      "6000 / train: 2.482361078262329 / dev: 2.5140342712402344\n",
      "6200 / train: 2.4822936058044434 / dev: 2.514019250869751\n",
      "6400 / train: 2.482227087020874 / dev: 2.514005422592163\n",
      "6600 / train: 2.4821617603302 / dev: 2.5139918327331543\n",
      "6800 / train: 2.4820969104766846 / dev: 2.513979196548462\n",
      "\n",
      "Initialized the network, reg=0.001\n",
      "0 / train: 3.734525680541992 / dev: 3.745314121246338\n",
      "200 / train: 2.667250394821167 / dev: 2.684072256088257\n",
      "400 / train: 2.5813701152801514 / dev: 2.600278615951538\n",
      "600 / train: 2.549004554748535 / dev: 2.569026231765747\n",
      "800 / train: 2.531620740890503 / dev: 2.552553415298462\n",
      "1000 / train: 2.5207266807556152 / dev: 2.5424628257751465\n",
      "1200 / train: 2.5132944583892822 / dev: 2.535769462585449\n",
      "1400 / train: 2.507920265197754 / dev: 2.5310816764831543\n",
      "1600 / train: 2.5038564205169678 / dev: 2.527653694152832\n",
      "1800 / train: 2.500674247741699 / dev: 2.5250589847564697\n",
      "2000 / train: 2.498115062713623 / dev: 2.5230422019958496\n",
      "2200 / train: 2.4960122108459473 / dev: 2.52144193649292\n",
      "2400 / train: 2.4942545890808105 / dev: 2.5201520919799805\n",
      "2600 / train: 2.492764949798584 / dev: 2.519099235534668\n",
      "2800 / train: 2.4914870262145996 / dev: 2.5182318687438965\n",
      "3000 / train: 2.490380048751831 / dev: 2.5175116062164307\n",
      "3200 / train: 2.489413022994995 / dev: 2.5169100761413574\n",
      "3400 / train: 2.4885613918304443 / dev: 2.5164053440093994\n",
      "3600 / train: 2.487806558609009 / dev: 2.5159802436828613\n",
      "3800 / train: 2.487133264541626 / dev: 2.5156216621398926\n",
      "4000 / train: 2.4865293502807617 / dev: 2.515317916870117\n",
      "4200 / train: 2.485985040664673 / dev: 2.5150604248046875\n",
      "4400 / train: 2.485491991043091 / dev: 2.5148425102233887\n",
      "4600 / train: 2.4850428104400635 / dev: 2.5146572589874268\n",
      "4800 / train: 2.484632730484009 / dev: 2.514500856399536\n",
      "5000 / train: 2.4842562675476074 / dev: 2.514368772506714\n",
      "5200 / train: 2.4841842651367188 / dev: 2.5143446922302246\n",
      "5400 / train: 2.484113931655884 / dev: 2.5143215656280518\n",
      "5600 / train: 2.4840450286865234 / dev: 2.5142996311187744\n",
      "5800 / train: 2.4839766025543213 / dev: 2.5142781734466553\n",
      "6000 / train: 2.483909845352173 / dev: 2.5142571926116943\n",
      "6200 / train: 2.4838435649871826 / dev: 2.51423716545105\n",
      "6400 / train: 2.4837779998779297 / dev: 2.5142176151275635\n",
      "6600 / train: 2.4837143421173096 / dev: 2.5141990184783936\n",
      "6800 / train: 2.4836513996124268 / dev: 2.514180898666382\n",
      "\n",
      "Initialized the network, reg=0.01\n",
      "0 / train: 3.826554775238037 / dev: 3.8289740085601807\n",
      "200 / train: 2.677434206008911 / dev: 2.6829142570495605\n",
      "400 / train: 2.589998960494995 / dev: 2.5978283882141113\n",
      "600 / train: 2.557638168334961 / dev: 2.5666518211364746\n",
      "800 / train: 2.5406057834625244 / dev: 2.5505239963531494\n",
      "1000 / train: 2.5300984382629395 / dev: 2.5407323837280273\n",
      "1200 / train: 2.522996664047241 / dev: 2.5342109203338623\n",
      "1400 / train: 2.5178964138031006 / dev: 2.529589891433716\n",
      "1600 / train: 2.5140700340270996 / dev: 2.526167154312134\n",
      "1800 / train: 2.5111043453216553 / dev: 2.523545265197754\n",
      "2000 / train: 2.5087461471557617 / dev: 2.5214850902557373\n",
      "2200 / train: 2.506833553314209 / dev: 2.519834518432617\n",
      "2400 / train: 2.5052554607391357 / dev: 2.5184900760650635\n",
      "2600 / train: 2.5039360523223877 / dev: 2.517380475997925\n",
      "2800 / train: 2.5028183460235596 / dev: 2.5164542198181152\n",
      "3000 / train: 2.501861810684204 / dev: 2.5156726837158203\n",
      "3200 / train: 2.5010359287261963 / dev: 2.515007495880127\n",
      "3400 / train: 2.500316619873047 / dev: 2.5144362449645996\n",
      "3600 / train: 2.499685287475586 / dev: 2.5139427185058594\n",
      "3800 / train: 2.4991281032562256 / dev: 2.5135133266448975\n",
      "4000 / train: 2.4986326694488525 / dev: 2.5131378173828125\n",
      "4200 / train: 2.49819016456604 / dev: 2.5128071308135986\n",
      "4400 / train: 2.4977927207946777 / dev: 2.512515068054199\n",
      "4600 / train: 2.497434616088867 / dev: 2.5122556686401367\n",
      "4800 / train: 2.497110366821289 / dev: 2.5120246410369873\n",
      "5000 / train: 2.4968156814575195 / dev: 2.5118179321289062\n",
      "5200 / train: 2.4967598915100098 / dev: 2.5117790699005127\n",
      "5400 / train: 2.4967052936553955 / dev: 2.5117411613464355\n",
      "5600 / train: 2.4966516494750977 / dev: 2.511704206466675\n",
      "5800 / train: 2.496598720550537 / dev: 2.5116677284240723\n",
      "6000 / train: 2.496547222137451 / dev: 2.5116324424743652\n",
      "6200 / train: 2.4964962005615234 / dev: 2.5115973949432373\n",
      "6400 / train: 2.496445894241333 / dev: 2.511563301086426\n",
      "6600 / train: 2.496397018432617 / dev: 2.5115301609039307\n",
      "6800 / train: 2.4963486194610596 / dev: 2.5114972591400146\n",
      "\n",
      "Initialized the network, reg=0.1\n",
      "0 / train: 3.9188268184661865 / dev: 3.822147846221924\n",
      "200 / train: 2.7432894706726074 / dev: 2.6765010356903076\n",
      "400 / train: 2.655092239379883 / dev: 2.5946459770202637\n",
      "600 / train: 2.621635675430298 / dev: 2.5653207302093506\n",
      "800 / train: 2.60391902923584 / dev: 2.550619125366211\n",
      "1000 / train: 2.5931196212768555 / dev: 2.5420849323272705\n",
      "1200 / train: 2.5860183238983154 / dev: 2.5367019176483154\n",
      "1400 / train: 2.581132173538208 / dev: 2.533123254776001\n",
      "1600 / train: 2.577667474746704 / dev: 2.530656337738037\n",
      "1800 / train: 2.5751571655273438 / dev: 2.528909206390381\n",
      "2000 / train: 2.5733087062835693 / dev: 2.527646064758301\n",
      "2200 / train: 2.571930408477783 / dev: 2.526716947555542\n",
      "2400 / train: 2.570892333984375 / dev: 2.526024580001831\n",
      "2600 / train: 2.570103883743286 / dev: 2.5255019664764404\n",
      "2800 / train: 2.5695009231567383 / dev: 2.5251035690307617\n",
      "3000 / train: 2.569037437438965 / dev: 2.524797201156616\n",
      "3200 / train: 2.5686793327331543 / dev: 2.524559736251831\n",
      "3400 / train: 2.5684010982513428 / dev: 2.524373769760132\n",
      "3600 / train: 2.5681846141815186 / dev: 2.5242273807525635\n",
      "3800 / train: 2.5680155754089355 / dev: 2.524111747741699\n",
      "4000 / train: 2.567882776260376 / dev: 2.524019718170166\n",
      "4200 / train: 2.5677785873413086 / dev: 2.5239458084106445\n",
      "4400 / train: 2.5676968097686768 / dev: 2.5238864421844482\n",
      "4600 / train: 2.567631959915161 / dev: 2.5238382816314697\n",
      "4800 / train: 2.5675809383392334 / dev: 2.523799419403076\n",
      "5000 / train: 2.5675406455993652 / dev: 2.5237674713134766\n",
      "5200 / train: 2.567533493041992 / dev: 2.523761749267578\n",
      "5400 / train: 2.5675268173217773 / dev: 2.523756265640259\n",
      "5600 / train: 2.5675201416015625 / dev: 2.5237512588500977\n",
      "5800 / train: 2.567514181137085 / dev: 2.5237460136413574\n",
      "6000 / train: 2.5675086975097656 / dev: 2.5237412452697754\n",
      "6200 / train: 2.567502975463867 / dev: 2.5237364768981934\n",
      "6400 / train: 2.567497730255127 / dev: 2.5237321853637695\n",
      "6600 / train: 2.5674924850463867 / dev: 2.5237278938293457\n",
      "6800 / train: 2.567487955093384 / dev: 2.523723840713501\n",
      "\n",
      "Initialized the network, reg=1.0\n",
      "0 / train: 4.798354148864746 / dev: 3.8036999702453613\n",
      "200 / train: 2.9084832668304443 / dev: 2.7009098529815674\n",
      "400 / train: 2.8163726329803467 / dev: 2.6686925888061523\n",
      "600 / train: 2.8070552349090576 / dev: 2.664703845977783\n",
      "800 / train: 2.8060171604156494 / dev: 2.663970947265625\n",
      "1000 / train: 2.805896520614624 / dev: 2.6638050079345703\n",
      "1200 / train: 2.805882215499878 / dev: 2.6637628078460693\n",
      "1400 / train: 2.805880546569824 / dev: 2.6637513637542725\n",
      "1600 / train: 2.805880308151245 / dev: 2.663748025894165\n",
      "1800 / train: 2.805880308151245 / dev: 2.6637470722198486\n",
      "2000 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "2200 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "2400 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "2600 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "2800 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "3000 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "3200 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "3400 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "3600 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "3800 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "4000 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "4200 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "4400 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "4600 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "4800 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "5000 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "5200 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "5400 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "5600 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "5800 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "6000 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "6200 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "6400 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "6600 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "6800 / train: 2.805880308151245 / dev: 2.6637465953826904\n",
      "\n",
      "Initialized the network, reg=10.0\n",
      "0 / train: 13.893353462219238 / dev: 3.776543617248535\n",
      "200 / train: 3.1431334018707275 / dev: 3.0349411964416504\n",
      "400 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "600 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "800 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "1000 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "1200 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "1400 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "1600 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "1800 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "2000 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "2200 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "2400 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "2600 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "2800 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "3000 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "3200 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "3400 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "3600 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "3800 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "4000 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "4200 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "4400 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "4600 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "4800 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "5000 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "5200 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "5400 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "5600 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "5800 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "6000 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "6200 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "6400 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "6600 / train: 3.1431334018707275 / dev: 3.034940481185913\n",
      "6800 / train: 3.1431334018707275 / dev: 3.034940481185913\n"
     ]
    }
   ],
   "source": [
    "for reg in regi:\n",
    "    \n",
    "    step = 0\n",
    "    lossi, idxs = [], []\n",
    "    \n",
    "    # Initialize the network\n",
    "    seed = torch.Generator().manual_seed(10110609)\n",
    "    W = torch.randn((len_alphabet*len_alphabet, len_alphabet), requires_grad=True, device=device)\n",
    "    print(f\"\\nInitialized the network, {reg=}\")\n",
    "    \n",
    "    for i in range(7000):\n",
    "\n",
    "        # forward propogation\n",
    "        xenc = F.one_hot(X_train, num_classes=len_alphabet*len_alphabet).float()\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdims=True)\n",
    "        loss = -probs[torch.arange(train_size), y_train].log().mean() + reg*(W**2).mean() # last part is regularization\n",
    "\n",
    "        # evalute loss on the dev set\n",
    "        loss_dev = evaluate(X_dev, y_dev, dev_size)\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            print(f\"{i} / train: {loss.item()} / dev: {loss_dev.item()}\")\n",
    "\n",
    "        # backward propogation\n",
    "        W.grad = None\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        lr = 50 if i < 5000 else 10 # learning rate decay\n",
    "        W.data += -lr * W.grad\n",
    "\n",
    "        # track params\n",
    "        lossi.append(loss.item())\n",
    "        idxs.append(step)\n",
    "        step += 1\n",
    "        \n",
    "    losses.append([idxs, lossi])\n",
    "    Wreg.append(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the loss metrics\n",
    "with open(\"losses.pkl\", \"wb\") as file:\n",
    "    pickle.dump(losses, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Wreg.pkl\", \"wb\") as file:\n",
    "    pickle.dump(Wreg, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the model and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"losses.pkl\", \"rb\") as file:\n",
    "  losses = pickle.load(file)\n",
    "  \n",
    "with open(\"Wreg.pkl\", \"rb\") as file:\n",
    "  Wreg = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
